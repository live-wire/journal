# Questions from `paper_4` :robot: 

**Q: A good scientific paper that is written to showcase a newly discovered ML model will be further improved if**
- the results presented in the paper are backed by an appendix which allows the readers to reproduce said results.
- mathematical formulas are included whenever possible, thus strengthening the rigour with which every sentence is written.
- all intuitive explanations of the novelties of the model are replaced with technical jargon.
- you drop all the effors of using a writing style that is accessible to researchers of other ML areas.
* `[ A ]`


---

**Q: Which of the following is a best practice that every machine learning paper should follow?**
- Separate speculation from facts.
- Always perform ablation to better understand a method.
- Assist the reader with the comprehension of technical terms by using terms expressed in everyday conversation.
- All of the above.
* `[ A ]`


---

**Q: Which of the following is not a trend in ML scholarship in Z. C. Lipton’s and J. Steinhardt’s paper ‘Troubling Trends in Machine Learning Scholarship?**
- Misuse of language
- Training on the test set
- Mathiness
- Explanation vs. Speculation
* `[ B ]`


---

**Q: What is not a troubling trend in Machine Learning Scholarship?**
- Misuse of language
- Failure to identify the sources of empirical gains
- Failure to distinguish between explanation and speculation
- Underuse of mathematic expressions
* `[ D ]`


---

**Q: What do the authors of “Troubling trends in machine learning scholarship” mean with overloading technical terminology?**
- The usage of too many technical terms makes articles tough to understand.
- Technical terms are being used in imprecise or contradictory ways.
- The usage of many technical terms to give a false sense of depth to the article.
- None of the above.
* `[ B ]`


---

**Q: What are three practices that are common in the strongest empirical papers?**
- Suitcase words, error analysis, robustness checks.
- Ablation studies, error analysis, mathiness.
- Suitcase words, ablation studies, robustness checks.
- Error analysis, robustness checks, ablation studies.
* `[ D ]`


---

**Q: Which of the following properties does Not belong to the papers best serve their readers? **
- They provide intuition to aid the readers understanding, but clearly distinguish it from stronger conclusions supported by evidence; 
- They describe empirical investigations that consider and rule out alternative hypotheses; 
- They make clear the relationship between theoretical analysis and intuitive or empirical claims; 
- They use irrefutable experimental conclusions to empower the reader, choosing terminology to avoid misleading or unproven connotations, collisions with other definitions, or conflation with other related but distinct concepts.
* `[ D ]`


---

**Q: According to Lipton and Steinhardt, in their publication on "troubling trends" in Machine Learning literature,**
- formal math notation should not be used in theoretical proofs.
- authors should integrate ablation studies into their publications only when strictly necessary.
- the frequent connection made between complex models and empirical gains is concerning.
- None of the above.
* `[ C ]`


---

**Q: Which of the following is NOT a troubling trend as mentioned in the paper?**
- explanation vs speculation
- mathiness
- incorrect citations
- misuse of language
* `[ C ]`


---

**Q: Which practice is not suggested to authors in order critically analyze their work?**
- Conduct error analysis
- Conduct ablation studies
- Conduct robustness checks
- Conduct a feasibility study
* `[ D ]`


---

**Q: Which of the following elements is not necessarily an element of a robust paper?**
- Ablation studies.
- Error analysis.
- Extensive use of mathematical tools and notation.
- Robustness checks.
* `[ C ]`


---

**Q: Which of the following patterns is not (according to the authors) between the troubling trends in ML scholarship?**
- Failure to identify real sources of empirical gains
- Misleading terminology used in scientific papers
- Delay in the pubblication of new studies and results
- Excessive or wrong use of mathematics
* `[ C ]`


---

**Q: The paper “Troubling Trends in Machine Learning Scholarship” strongly recommends:**
- To be aware that mathematical concepts in a paper should only be putted there if they really add something to the paper, not to convey researches of technical depth (“mathiness”).
- To clearly check if stamens of other papers are based on speculations or on scientific evidence when reading (or using) a paper.
- To be aware that you do not ‘overload technical terminology’ where misuse consists of taking a term that holds precise technical meaning and using it in an imprecise or contradictory way.
- All of the above.
* `[ D ]`


---

**Q: No free lunch theorem is commonly invoked as a justification for using heuristic methods without guarantees, even though the theorem does not formally
preclude guaranteed learning procedures. What statements  and implications of NFLT are true?

statement 1: If an algorithm performs better than random search on some class of problems then in must perform worse than random search on the remaining problems.

statement 2:  The use of domain knowledge can improve performance, at the cost of generality.

statement 3:  We are generally not going to find off the shelf algorithms that fit perfectly to our data. We are going to have to architect the algorithm to better fit the data .

statement 4: The beauty of neural nets is that they are modifiable in architecture, allowing us to engineer new solutions specific to the problem at hand, but then become specialised as you settle on a good configuration.**
- 1
- 1 and 3
- All statements above
- 3
* `[ C ]`


---

**Q: "Troubling Trends in Machine Learning Scholarship" describes heuristics which hope to improve the quality of research papers. Which of the following claims, 
 which argue that such heuristics are unnecessary, was presented in the paper? (Hint: It was compared to Gradient Descent)**
- People in academia will always be too greedy to adjust their research methods for the sake of their field
- Dissemination information is hard to standardize because people in the academic communities learn differently, interpret language differently, and may have different preferences
- The community will self-correct confusing, unsupported, or incorrect information from low-quality papers, which will outpace research in a more controlled community
- People performing research in more technical fields should not be bothered to help the learning process of the newer researchers
* `[ C ]`


---

**Q: What is the meaning of deconvolution (a.k.a up-convolution)?**
- This is a transpose convolution
- This is a convolutional network which learns the inverse
- This is an upgraded loss function
- That is the results of two merge convolutions
* `[ A ]`


---

**Q: What is meant by Mathiness in this paper?**
- The mixture of math and natural language without tight links
- The use of using complex math to bully people in agreeing with the paper
- The lack of rigorousness in the mathematical proofs
- The use of mathematical terms for concepts which are not reducible to mathematical terms
* `[ A ]`


---

**Q: Which of the following is NOT an instance of “Mathiness”, according to the authors?**
- Invoking theory without a concrete need, only to make the paper more technical.
- Mixing math and informal language in an unclear way, making the reader believe that something is a technical fact when instead it is not.
- Showing long correct proofs or theorems in a paper.
- Abusing mathematics to formalize something that could be better explained by means of informal language without invoking math.
* `[ C ]`


---

**Q: Which of the following statements is FALSE:**
- Training set overfitting refers to a (large) difference between the accuracy on the training set and the accuracy on the test set.
- Test set overfitting refers to the gap between the accuracy on the test set and the accuracy on the underlying data distribution.
- Recent progress in machine learning in terms of performance on the CIFAR-10 dataset is not a result of test set overfitting.
- Test set overfitting can easily be measured by witholding some data from the test and training set and testing the classifier on this data.
* `[ D ]`


---

**Q: How can one combat the overuse of "mathiness" when writing a scientific paper(on Deep learning)?**
- By separating speculation from fact.
- By isolating the sources of empirical gains
- By covering it in a down-to-earth manner with numerous clear connections to applied empirical problems
- By limiting the use of suggestive definitions.
* `[ C ]`


---

**Q: In the paper "Troubling Trends in Machine Learning Scholarship" what do the authors suggest to other Machine Learning authors?**
- To think “what worked?” and “why?” in their algorithm
- To determine how well their algorithm works
- When they are reviewers to go easier on others
- Emphasize on making their research more marketable  
* `[ A ]`


---

**Q: Regarding the machine learning peer review process, what is the problem of using a high number of techniques together in an empirical model without proper thorough studies?**
- Mixing a lot of empirical techniques decrease the possible solutions of the problem
- It shows all the unnecessary changes in the empirical experiment
- It obscures the source of the empirical gains and the real change responsible for the improvement of results
- A good ablation analyses decrease the possibilities of finding the source of the empirical gain
* `[ C ]`


---

**Q: How does the paper suggest to identify sources of empirical gains?**
- ablation
- robustness checks 
- qualitive error analysis
- all of the above
* `[ D ]`


---

**Q: Which of the following statements is FALSE?**
- The use of suitcase words might result in papers that appear to be in dialogue with each other but have different concepts in mind
- Speculations should not be formulated as explanations, because they might then be interpreted as authoritative
- Failure to identify the sources of empirical gains might emphasize hyper-parameter tuning while gains actually stem from modifications to neural architectures
- As an author, focusing on ‘what worked?’ and ‘why?’ instead of ‘how well?’ is a good idea for writing a good paper
* `[ C ]`


---

**Q:  Which one is not correct statement about suitcase words of Machine learning paper?**
- It is related to emotion machine
- interpretability is a suitcase word
- mental processes such as consciousness, thinking, attention are related to suitcase word
- words suit more with ML approaches are suitcase words
* `[ D ]`


---

**Q: Which of the below statements about the consequence of overloading technical terminology in Deep Learning is false?**
- Terms may be used in an imprecise way.
- Terms may be confused by the original meaning of the word.
- Redefinition of terms may conceal lack of progress by referring to something easier instead.
- All of the above are false.
* `[ D ]`


---

**Q: Which troubling trend in machine learning has not been "properly" addressed in the paper "Do CIFAR-10 Classifiers Generalize to CIFAR-10?"**
- "Explanation / Speculation" : on dataset distribution shift causing decrease in test error
- "Source of empirical results" : Identifying the source of increase in empirical test errors
- "Mathiness" : Mathematical equations to show linear trend between old and new test errors
- "Misuse of language" : Usage of suitcase words like "generalization"
* `[ C ]`


---

**Q: Which of the patterns below is not one in ML articles?**
- Failure to distinguish between explanation and speculation
- Failure to identify empirical gains
- Mathiness
- Misuse of language
* `[ B ]`


---

**Q: The purpose of the paper "Do CIFAR-10 Classifiers Generalize to CIFAR-10?" is to check if the accuracy claimed by the different classifiers over the time is truly reliable. The result of the new tests showed that the accuracy...**
- Increases
- Decreases
- Remaines the same
- It is not possible to say because there is not a clear trend
* `[ B ]`


---

**Q: Which of the following conditions is not the misuse of language?**
- Suggestive Definitions
- Overloading Technical Terminology
- Suitcase Words
- Mathiness
* `[ D ]`


---

**Q: Troubling trends do NOT include:**
- Failure to identify the sources of empirical gains.
- Tangling of formal and informal claims.
- Taking a term that holds precise technical meaning and using it in an imprecise or contradictory way.
- Focusing merely on experiments instead of theories.
* `[ D ]`


---

**Q: What is a common way of language misuse in machine learning?**
- Suggestive definitions
- Overloaded terminology
- Suitcase words
- All of the above
* `[ D ]`


---

**Q: What is meant by "Mathiness"?**
- The paper is harder to understand for newcomers in a certain research area
- Weak arguments can be bolstered by the appearance of technical depth by using  a lot of math.
- Mathematical formulas that are not nicely separated from continuous text
- Very detailed mathematical explanation which clarifies an otherwise vague statement
* `[ B ]`


---

**Q: What would be an example of "Failure to Identify the Sources of Empirical Gains"?**
- Some papers abuse mathematics to convey technical depth
- Miscalculating and overestimating the true error of a classifier
- Emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning
- Choosing a neural network topology without reasoning
* `[ C ]`


---

**Q: In the paper "Troubling Trends in Machine Learning Scholarship" the authors reference the misuse of terminolgy by taking a term that holds precise technical meaning and using it in an imprecise or contradictory way. With respect to the term "deconvolution", what incorrect meaning has the term taking on in newer machine learning papers?**
- Reversing a Convolution
- Transposing a Convolution (also called up-convolutions)
- Inverting a Convolution
- Finding the eigenvalue decomposition of a Convolution
* `[ B ]`


---

**Q: Many papers emphasize complex models and fancy mathematics to satisfy reviewers for constructing new techniques. However, there are many other ways to show. Which of the following ways are NOT the way that empirical advances often come out in?**
- clever problem formulations
- reproduce complex models
- scientific experiments
- optimization heuristics
* `[ B ]`


---

**Q: Comparisons with ‘human-level’ performance (e.g. comparing an algorithms error rate to that of a human) can:**
- Cause better understanding of the research, so they should be used.
- Cause better connection to the reader of your research, so they should be used.
- Portray a false sense of capabilities, so they should not be used.
- Allow you to express an idea in fewer words, so they should be used.
* `[ C ]`


---

**Q: Example: "surpassing human abilities and effectively proving that
bigger data leads to better decisions". Under which of these four patterns falls this example of subjects that are trending in machine learning?**
- Failure to identify the sources of empirical gains, e.g. emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning.
- Misuse of language, e.g. by choosing terms of art with colloquial connotations or by overloading established technical terms.
- Mathiness: the use of mathematics that obfuscates or impresses rather than clarifies, e.g. by confusing technical and non-technical concepts.
-  Failure to distinguish between explanation and speculation.
* `[ B ]`


---

**Q: Which of the following statements is not a risk when the ML field keeps making the mistakes mentioned in 'Troubling trends in machine learning scholarship'?**
- Research in the ML field will turn out not to be reproducable
- The lawmakers will create laws about ML and AI that are unnecessary
- Some facts that have never been proven will be assumed as truth by the ML community
- Robots using ML may become too powerful
* `[ D ]`


---

**Q: Why should there be intervened in the field of ML?**
- The consequences of literature in the field do not align with its causes.
- Flawed scholarship infects the entire field of Machine Learning.
- There is no 'free lunch'. However, many pseudo-scientists believe that one learner is better than another, which is wrong.
- Both A and B.
* `[ D ]`


---

**Q: Which of the following is not considered a troubling trend in the context of machine learning scholarship?**
- Forming a theory or conjecture without firm evidence and relying on it to prove a point. 
- The use of too many references which leads to confusion on information source.
- Use of mathematics that obfuscates or impresses rather than clarifies a concept.
- Failure to show what tweaks in a method have caused an improvement in performance. 
* `[ B ]`


---

**Q: What practice is NOT to be followed during a research, according to (Lipton Steinhardt, 2018)? **
- Error analysis
- Apply tweaks without ablation studies
- Robustness checks
- Ablation studies
* `[ B ]`


---

**Q: In the paper: "Troubling Trends in Machine Learning Scholarship", which of the following according to the authors is NOT a benefit of rigorous empirical experiments on machine learning models/methods**
- It helps to identify which steps produce the greatest increase in prediction accuracy
- It can provide new and deeper insight into existing models and methods
- It can provide a means of validating mere speculations
- None of the above
* `[ D ]`


---

**Q: The paper "Troubling Trends in Machine Learning Scholarship" gives suggestions to authors of ML articles. Which of the following suggestions was NOT given in this article?**
- Authors should put more equations in their papers.
- Authors should ask "What worked?" and "Why?" rather than just "How well?".
- Authors should ask themselves: "Would I rely on this explanation for making predictions or for getting a system to work?".
- Authors should make it clear which problems are open or closed.
* `[ A ]`


---

**Q: Which option is not a part of language misuse in machine learning?**
- suggestive definitions
- overloaded terminology
- Model progression
- suitcase words
* `[ C ]`


---

**Q: Which of the following are NOT troubling trends in Machine Learning Scholarship?**
- Failure to distinguish between explanation and speculation.
- Failure to identify the sources of empirical gains
- Misuse of language
- None of the above (all above are troubling trends)
* `[ D ]`


---

**Q: What should be included in a strong empirical evaluation of a DL performance?**
- error analysis
- ablation studies
- robustness checks
- all of the above
* `[ D ]`


---

**Q: What techniques that are used to improve model performance, empirically, are potentially harmful to the development of Machine Learning?**
- Optimization heuristics
- Data preprocessing techniques
- Extensive hyper-parameter tuning
- It's not about a specific method being used, it's about the fact that some methods are sometimes not investigated what their impact is.
* `[ D ]`


---

**Q: What should be NOT focused on when writing a scientific article about a ML model?**
- Providing the reader with intuition to better understand the problem.
- Describing empirical investigations to accept or rule out alternative hypotheses.
- Providing strong conclusions even when evidence is lacking.
- All of the above.
* `[ C ]`


---

**Q: Which of the following trends is not troubling according the paper?**
- Using complex mathmetical functions
- Usage of suggestive definitions
- Disguising speculations as explanations
- Missing ablation studies
* `[ A ]`


---

**Q: When using a term that holds precise technical meaning in a scientific paper in an imprecise or contradictory way, is called “Overloading Technical Terminology”. What can you, the author of a new scientific paper, do to prevent overloading terminology?**
- a) over-generalize the term to something the reader recognizes
- b) assign a suggestive term to the technical meaning you want to describe
- c) only use the term if you want to describe the original meaning
- d) there is nothing wrong with overloading technical terminology
* `[ C ]`


---

**Q: The problem with machine learning nowadays is there is an increasing trend in flawed scholarship. Consider following two statements:

\begin{enumerate}
	\item Researchers tend to overuse mathematics when talking about machine learning.
	\item Researchers tend to speculate results.
\end{enumerate}

Which statements are true or false?**
- 1 true and 2 true.
- 1 true and 2 false.
- 1 false and 2 false.
- 1 false and 2 true.
* `[ A ]`


---

**Q: Which of the following trends in Machine Learning is NOT a troubling trend?**
- Speculation
- Failure of identifying sources of empirical gains
- Mathiness
- The rapid development of machine learning programming languages
* `[ D ]`


---

**Q: Choose the correct statement about improving quality of papers.**
- Researchers should present less tweaks in papers to clarify the source of improvement.
- More speculations should be used in the guise of explanations to impart intuitions.
- It is a good practice to use only mathematical descriptions in order to make the statements formally verifiable.
- Overloading technical terminology should be avoided, because readers can get confused of using everyday words in technical context.
* `[ A ]`


---

**Q: What is NOT a common pitfall that should be avoided according to the “Troubling Trends in Machine Learning Scholarship” paper:**
- Overloading established technical terms
- Confusing technical and non-technical concepts by using math.
- Reporting values for hyper-parameters without exhaustive search over their possible values
- Reporting speculations as facts
* `[ C ]`


---

**Q: Which of following statements is false?**
- Misuse of language appears to be trending in ML scholarships. There are two kinds of language misuse in ML, which are suggestive definitions and overloaded terminology.
- When mathematical and natural language statements are mixed without clear accounting of their relationship, both the prose and the theory can suffer. This tangling of formal and informal claims is called mathiness.
- Authors propose many tweeks absent proper studies, obscuring the source of emperical gains, which seems a troubling trend in ML Scholarships.
-  Explanatin vs. Speculation seems to be a troubling trend in ML scholarships.
* `[ A ]`


---

**Q: Which of the following is one of the troubling trends in Machine Learning Scholarship ?**
- Failure to identify and explain the empirical gains and its advantages.
- Failure to identify and explain the experiments/research in an accurate mathematical way, due to which the performance gains of the proposed model are unexplained/unclear.
- Failure to identify and explain the exact sources in the proposed model which lead to the gain in performance.
- All of the above.
* `[ C ]`


---

**Q: According to the authors, why are suitcase words harmful in literature?**
- Using suitcase words leads to overestimating the capabilities of current systems
- Suitcase words often have no descriptive value towards the results of the research
- Suitcase words promise performance of the system that is not available
- Overinflation of words leads to the spread of wrong terminoligy in literature
* `[ A ]`


---

**Q: Which of the following is not a pattern that is trending in ML scholarship?**
- Failure to distinguish between explanation and speculation
- Failure to identify the source of empirical gains
- Mathiness: the use of mathematics that obfuscates or impresses rather than clarifies
- Simplifying texts to such a degree that it conveys significantly less important information
* `[ D ]`


---

**Q: Which is not one of the aspect of misuse of language in the recent machine learning literature ?**
- Mathiness
- Overloaded terminology
- Suitcase words
- Suggestive definition
* `[ A ]`


---

**Q: Consider the case that you are a scientist that is planning to publish a paper in a field of Deep learning. What characteristics your paper SHOULD have in order to avoid misleading a deep learning community?**
- Ask “what worked?” and “why?”, rather than just “how well?”  
- Try to change natural language statements into mathematical statements as much as possible.
- Propose any number of tweaks as long as system performance is improved.
- Touch topics that could interest startups and corporations.
* `[ A ]`


---

**Q: Which of the following is CORRECT?**
- The arguments in your paper becomes less important once you have found nice results.
- When you are proposing a novel algorithm to tackle a problem, it is acceptable to explain it with a large number of equations.
- Error analysis and ablation studies are good strategies for writing strong empirical papers.
- A good empirical paper always tries to trace the sources of empirical gains.
* `[ C ]`


---

**Q: Which of the following statements is not one of the four ideals that the authors enumerate for papers best serving readers that are interested in machine learning:**
- intuition is provided and separated from evidence.
- the relationship between theoretical analysis and intuitive or empirical claims is clearly explained.
- impressive mathematical formulas are shown (mathiness).
-  clear and distinct terminology is used.
* `[ C ]`


---

**Q: Which two advises are supported by the paper.
1. Adding extra math almost always makes a paper more clear.
2. When writing a paper the writer should aim to give insight instead of reporting results.**
- Both are NOT correct.
- Only 1 is correct
- Only 2 is correct 
- Both are correct
* `[ C ]`


---

**Q: Which of the following can not be interpreted as a cause for the troubling trends in ML scholarship?**
- The attitude adopted that "strong results excuse weak arguments"
- The great expansion of the ML community, which created problems like the mis-use or re-define of the language
- Misaligned incentives provided by investors and the press
- The failure to distinguish between explanation and speculation
* `[ D ]`


---

**Q: Does the rapid expansion of machine learning has an impact on the publication quality in the research area?**
- Yes, more low-quality papers are popping up.
- Yes, the rapid expansion of research led to higher quality results and reasoning.
- No, the overall quality stayed the same.
- Yes, the mathematical precision improved in the papers.
* `[ A ]`


---

**Q: Which of the following is not an example of troubling trends?**
- Obscuring the source of empirical gain by proposing a model with complex multiple combined innovations in networks architecture without proving that all of the changes were necessary for achieving the presented results
- Using deconvolution term as referring to transpose convolutions in GANs
- Insert into a paper a theorem to justify the empirical results even when the theorem conclusions do not actually support the main claim of the paper
- Sharing of a new idea without an ablation study even if conducting such a study is not feasible 
* `[ D ]`


---

**Q: Limitation in machine learnings are partly due to:

1. Time
2. Language
3. Over use of math**
- 1
- 1, 2
- 2,3
- 1,2,3
* `[ D ]`


---

**Q: Which is NOT cause of trends in the paper?**
- Complacency in the face of progress
- Rapid expansion of the community
- Short-term measure of success
- Unprofessional education in the schools
* `[ D ]`


---

**Q: Which of the following is an example of a troubling trend in machine learning scholarship?**
- Insufficient use of suitcase words
- Many ideas and claims lack precise mathematical description
- Failure to identify the sources of empirical gain
- Clear separation of fact from speculation
* `[ C ]`


---

**Q: Which of the following statements is TRUE according to the author?**
- The troubling trends cannot be self-corrected and needs urgent attention to tackle with them
- There is no counterarguments to the proposed troubling trends and suggestions
- Even though these problems can self-correct, debating is still needed
- Strong quantitative results should override weak arguments
* `[ C ]`


---

**Q: The hype in Machine Learning in the recent past has led junior and senior researchers to adopt ill-advised strategies when analyzing and reporting results of their projects/experiments. It is thus crucial to raise awareness of students when it comes to assessing the findings of recent research and develop their critical thinking. Which of the following facts could be suggestive of a flawed research publication in the Machine Learning domain?**
- It relies on empirical scrutiny of preceding advances in the field and does not involve novel mathematical tools
- It uses complex terminology and convoluted notions to establish its core arguments
- It makes strong assertions without conveying uncertainty when using assumptions drawn from immature research
- It makes use of simplifying  physical-world analogies  aiming at the intuition of the reader in order to clarify or strengthen its statements
* `[ C ]`


---

**Q: What are suitcase words?**
- Words used incorrectly in the context
- Synonyms
- Words appearing to have the same meaning
- Words appearing to have multiple meanings
* `[ D ]`


---

**Q: Which choice is not a necessary desirable characteristics for papers in the field of machine learning:**
- provide intuition to aid the reader’s understanding, but clearly distinguish it from
stronger conclusions supported by evidence
- provide intuition to aid the reader’s understanding, but clearly distinguish it from
stronger conclusions supported by evidence
-  make clear the relationship between theoretical analysis and intuitive or empirical claims
- give explanation of modifications to neural architectures when gains stem from hyper-parameter tuning
* `[ D ]`


---

**Q: Concerning Misuse of Language in ML papers, what statement is TRUE?**
- Overloading the technical terms is one of the main issue in terms of Misuse of Language in ML papers
- Statements comparing results of classifiers with “human-level” performance give clear view of capabilities of current Neural Networks
- “Generalization” as a word, is only used as technical term in ML papers
- In ML papers, “Deconvolution” describes process of reversing the convolution
* `[ A ]`


---

**Q: Which is not identified as a bad trade of ML scholarships?**
- Failure to distinguish between explanation and speculation
- Failure to identify the sources of empirical gains
- Lack of obfuscating math
- Misuse of language
* `[ C ]`


---

**Q: According to the authors, what is not one of the manifistations of 'mathiness'?**
- The abuse of mathematics to bulldoze rather than to clarify.
- The use of mathematics when natural language can be used.
- The fact that authors neither use mathematics in a clearly formal nor informal way.
- The invokation of theory in overly broad ways.
* `[ B ]`


---

**Q: The authors mention multiple negative trends that are currently visible in Machine Learning papers. What is not a reason for these trends?**
- The ML community rapidly grows
- There are not enough experienced reviewers
- Authors go for short-term success
- Authors use to many difficult equations in there papers
* `[ D ]`


---

**Q: Which of the following is a disadvantage resulting from the rapid growth of the machine learning community?**
- Reviewers are overworked due to the increase of new papers to review.
- The increase in new, inexperienced authors results in papers containing flaws.
- There are not enough experienced reviewers compared to the amount of papers being written.
- All of the above.
* `[ D ]`


---

**Q: What is a remedy for the problem introduced by using “suitcase words”?**
- Do not use them.
- Use them sparingly.
- Cannot be resolved at all.
- Explicitly mention what each suitcase word means in the context of the discussion.
* `[ D ]`


---

**Q: Which of these is not one of the four 'patterns' described in the paper**
- Failure to distinguish between explanation and speculation
- Mathiness
- Irrelevant research
- Misuse of language
* `[ C ]`


---

**Q: Following the reasoning of the authors of "Troubling trends in Machine Learning Scholarship", which of the following is not believed by them to be a cause behind the emerging troubling trends?**
- Complacency in the face of progress
- The thinness of the reviewer pool
- Misaligned incentives 
- The misuse of language
* `[ D ]`


---

**Q: When a paper is presented with gains on performance, which if the followings is a common mistake?**
- The authors always assume is from the better performing model
- The results are nor presented with confidence intervals
- The authors fail in presenting the source of the empirical gains
- None of the above
* `[ C ]`


---

**Q: Which are true?

I. Mathiness gives the amount of technical difficulty.

II. The problems that are trending in ML scholarship are (partially) due to an exponential growth in this field.**
- I
- II
- Both
- Neither
* `[ B ]`


---

**Q: Choose the correct statement.**
- Ablation studies can help in identifying near-optimal hyper parameters for a given model
- Any performance gains made to the existing model has to be explained by mathematical equations including any theorems if any
- In a paper, care must be taken to mention the precise technical term as well it's overloaded terms in the existing literature
- All the above statements are wrong
* `[ D ]`


---

**Q: Which one of the followings represent the less relevant characteristic on a paper in the optic of a reader.**
- Provides the foundational knowledge to help the reader’s understanding of the concepts.
- The number of references to other papers.
- Make use of clear language, avoiding misleading connotations or collisions with other definitions.
- Establish a clear relationship between theoretical analysis and empirical claims.
* `[ B ]`


---

**Q: In paper writing, which of the following statement is not right?**
- when it comes to Mathematics, more equation should be listed in paper in order to prove academic depth
- when it comes to Mathematics,claims that are neither formal or informal should be avoided.
- suggestive definitions,overloaded terminology, and suitcase words arethree common avenues of language misuse
- papers often offer speculation in the guise of explanations
* `[ A ]`


---

**Q: Which of the following patterns is not trending in machine learning scholarship?**
- Failure to distinguish between explanation and speculation
- Failure to identify the sources of empirical gains
- Researches that generate conceptual ideas are not distilling knowledge
- Mathiness: the use of mathematics that obfuscates rather than clarifies
* `[ C ]`


---

**Q: Which language misuse is not identified in Machine Learning?**
- Suggestive definitions
- Overloaded terminology
- Suitcase words
- Mathiness
* `[ D ]`


---

**Q: Which of the following has not been explicitly mentioned by the authors as a troubling trend in ML scholarship?**
- providing speculative statements in the guise of explanations, to persuade readers into blindly following the article
- lack of ablation studies to identify an actual source of improvement in results
- improper usage of theorems, equations and literary terms which confuses readers
- adjusting experimental data to achieve statistical significance
* `[ D ]`


---

**Q: Which does not cause the troubling trends in machine learning?**
- complacency in the face of progress
- the rapid expansion of the community
- the consequent thinness of the reviewer pool
- long-term measures of success
* `[ D ]`


---

**Q: What is not a solution to the failure to identify sources of empirical gains**
- Ablation studies
- Robustness checks
- Qualitative error analysis
- None of the above
* `[ D ]`


---

**Q: What are the practices found common in the strongest empirical papers?**
- Error analysis
- Ablation studies
- Robustness checks
- All of the above
* `[ D ]`


---

**Q: In machine learning papers, which of the following avenues is not an example of language misuse: **
- A suggestive term that is assigned a technical meaning
- Taking a term that holds precise technical meaning and using it in an imprecise or contradictory way
- Use of mathematics as a tool for scientific communication
- Suggestive definitions and overloaded terminology that contribute to the creation of new suit-case words. 
* `[ C ]`


---

**Q: Statement 1: There are three common kinds of language misuse in machine learning: anthropomorphic characterizations, overloaded terminology and suitcase words
Statement 2: The consequent thinness of the reviewer pool does not influence the trend of some bad writing behaviour in ML papers**
- Both statements are true 
- Statement 1 is true
- Statement 2 is true
- Both statements are wrong
* `[ D ]`


---

**Q: Which of the following trends is not stated by Zachary C. Lipton and Jacob Steinhardt as a troubling trend in machine learning scholarships?**
- Mathiness
- Explanation vs Speculation
- Using (too) much pictures
- Misuse of language
* `[ C ]`


---

**Q: What's a common mistake in Machine Learning papers?**
- Substituting intuition for explanation
- Bunching optimizations together and not performing ablation studies
- Non-technical and broad definitions
- All of the above
* `[ D ]`


---

**Q: Which of the following is not a common misuse of language in machine learning?**
- Suggestive definitions
- Concise language
- Suitcase words
- Overloading technical terminology
* `[ B ]`


---

**Q: How does the accuracy of a convolutional model decrease?**
- Increase hidden layers, this will improve the accuracy
- Descrease the hidden layers, this will improve the accuracy
- Use a single fully-connected non-linear layer and no convolutional layers.
- Node of the above
* `[ C ]`


---

**Q: According to Lipton Steinhardt, which practice is not to be followed during a research?**
- Ablation studies
- Check robustness
- Error analysis
- Apply tweaks without ablation studies
* `[ D ]`


---

**Q: In some papers, the author tends to give the false impression that a lot of work has been done by proposing several improvements, while the truth is that only one or few changes is actually responsible for the improvement.
Which of the following classification does this fact belong to?**
- Failure to distinguish between explanation and speculation
- Failure to identify the sources of empirical gains, e.g. emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning.
- Mathiness: the use of mathematics that obfuscates or impresses rather than clarifies, e.g. by confusing technical and non-technical concepts.
- Misuse of language, e.g. by choosing terms of art with colloquial connotations or by overloading established technical terms.
* `[ B ]`


---

**Q: Which of these practices should be avoided in a paper?**
- Error analysis
- Ablation studies
- Robustness checks
- Mathiness
* `[ D ]`


---

**Q: The term „deconvolution” is usually misused in deep learning literature. The correct meaning of „deconvolution” is:**
- The process of transposing a convolution
- The process of performing convolutions with different kernels
- The process of performing the same convolution twice
- The process of reversing a convolution
* `[ D ]`


---

**Q: Which of the following is a common avenue of language misuse in machine learning?**
- Suggestive definitions
- Overloaded terminology
- Suitcase words
- All of the above
* `[ D ]`


---

**Q: What can be meant by 'generalization'?**
- Generalization from train to test
- Generalization from one population to another
- Generalization from an experimental setting to the real
world
- All answers are correct
* `[ D ]`


---

**Q: In the paper “Troubling Trends in Machine Learning Scholarship” the authors emphasize the fact that “papers are most valuable to the community when they act in service of the reader, creating foundational knowledge and communicating as clearly as possible”. Considering the troubling patterns discussed in the paper, which of the following should be AVOIDED when writing a paper that best serves its readers?**
- Distinguishing between explanation and speculation.
- Clearly identifying the sources of empirical gain.
- Choosing terms with colloquial connotations and adding more meanings to terms that already have a precise technical meaning.
- Not overusing mathematical tools, as not all ideas require mathematical descriptions and natural language is equally indispensable for communicating, especially about intuitive or empirical claims.
* `[ C ]`


---

**Q: “the high dimensionality and abundance of irrelevant features. . . give the attacker more room to construct attacks”

Is the above statement an explanation or a speculation?**
- Explanation if experiments were conducted to measure the effect of dimensionality on attackability
- Speculation if experiments were conducted to measure the effect of dimensionality on attackability
- Explanation, irrespective of the experiments conducted
- Speculation, irrespective of the experiments conducted
* `[ A ]`


---

**Q: Why is it important to identify the sources of empirical gains?

I- Authors often apply a number of techniques and not all of them may contribute to the reported gains. Sometimes only one of the changes is actually responsible for improved results. 
II- Often unnecessary architecture modifications are emphasized without realizing that the reported gain is from hyperparameter tuning
III- Empirical study can help in uncovering new research dimensions **
- I and II
- II and III
- I and III
- I, II and III
* `[ D ]`


---

**Q: What convinces reviewers of the technical depth of a paper?**
- Intuitive simple equations
- Well written explanation that does not rely on equations as it is clear enough
- Hard to decipher equations adding layers of complexity
- Well reasoned arguments
* `[ C ]`


---

**Q: You proposed multiple explanations for the changes in a classifiers result, but you know that one factor has much greater impact above all others. You fell in the pitfall of: **
- Mathiness
- Speculation
- Failure to identify source of empirical gains
- Misuse of language
* `[ C ]`


---

**Q: Name a counter argument for : "you can’t argue with
success!"**
- There are no counter arguments
- succes is temporarly, the field changes.
- many aspects of the current culture are consequences of ML’s recent success, not its cause
- succes is based on specific triaining sets.
* `[ C ]`


---

**Q: Which statement is wrong?**
- This paper identified language misuse in machine learning research: suggestive definitions, overloaded terminology, and suitcase words.
- Overloaded terminology  refers to terms that may pack many different meanings, it creates the confusion to readers with different backgrounds.
- Suggestive definitions  occurs when authors coin suggestive terms that convey human qualities.
- This paper talks about Mathiness.
* `[ B ]`


---

**Q: What of the following is not a bad practise when writing a machine learning paper?**
- Mathiness
- Misuse of Language: suggestive definitions, overloading technical terminology and suitcase words
- Distinguishing between explanation and speculation
- Failing to identify sources of empirical gains
* `[ C ]`


---

**Q: Which of the following is not a patterns that appear to be trending in ML scholarschip:**
- Failure to distinguish between explanation and speculation. 
- Failure to identify the sources of empirical gains, e.g. emphasizing unnecessary modifications to neural architectures when gains actually stem form hyper-parameter tuning. 
- Providing intuition to aid the reader’s understanding. 
- Misuse of language, e.g. by choosing terms of art with colloquial connotations or by overloading established technical terms. 
* `[ C ]`


---

**Q: Mathiness is:**
- When a research paper only draws conclusions drawn from mathematical expressions.
- The method to present a solution when language statements will not suffice.
- When mathematical and natural language statements are mixed without a clear accounting of their relationship.
- When formulas are presented without defining the variables used.
* `[ C ]`


---

**Q: Which of the following is not an troubling trend among Machine Learning Scholarships**
- Choosing terms of art with colloquial conotations or by overlaoding established technical terms
- Failure to formulate a clear statement by using to complicated mathematics to impress the community
- Failure to distinquish between explanation and speculation
- Failure to properly explain what a deep learning algoritm does, such that others can learn from it.
* `[ D ]`


---

**Q: What are troubling trends in machine learning?**
- That quite often speculation is given as an explanation
- There is a failure to identify the source of emperical gains
- A missuse of mathematics called "mathiness"
- All of the above
* `[ D ]`


---

**Q: Which following way fail to identify the sources of empirical gains?**
- Ablation study
- Robustness check
- Hyperparameter tuning
- Qualitative error analysis
* `[ C ]`


---

**Q: Test set overfitting is a result of**
- Adapting model design choices to the test set (hyperparameter tuning)
- Having the test set be generated by a second (independent) classification system
- The distribution of the test set not matching the training distribution
- The test set being too small
* `[ A ]`


---

**Q: Which of the following statements is/are true about mathiness?

A Mathiness uses a mixture of words and symbols.
B Mathiness leaves room for slippage between statements in natural language versus formal language. **
- A
- B
- A and B
- None
* `[ C ]`


---

**Q: What is wrong about the following statement: "The Neural Network achieves dermatologist-level classification of skin cancer". **
- "Human-level" is a suggestive definition and it gives a false sense of the current capabilities.
- Classification is a suitcase word that packs together a variety of meanings, and should be avoided carefully
- Mathiness is introduced which makes the statement less clear
- The statement failed to identify the source of empirical gains 
* `[ A ]`


---

**Q: The Mathiness:**
- Is the use of mathematics to impress rather than clarify
- Is the mathematical background of a paper
- Is desirable for a competent paper
- Defines the amount of mathematical notations included in an article
* `[ A ]`


---

**Q: Mathiness could refer to**
- Excellent proofs in papers
- Advanced math level skills of the researcher
- Theorems used in the papers are false or used incorrectly
-  None of the above
* `[ C ]`


---

**Q: What is NOT a current issue in present Machine Learning scholarship?**
- Failure to distinguish between explanation and speculation.
- Failure to identify the sources of empirical gains.
- Failure to provide non-empirical conclusions.
- Misuse of language.
* `[ C ]`


---

**Q: What is NOT common avenues of language misuse in machine learning?**
- Suggestive deginition
- Overloaded terminology
- Suitcase words
- Deceptive description
* `[ D ]`


---

**Q: One of the following is the aim of machine learning**
- theoretically characterize what is learnable,
- to obtain understanding through empirically rigorous experiments
- to build a working system that has high predictive accuracy
- All 
* `[ D ]`


---

**Q: Which of the following statements indicate good practice that needs to be adapted
1)Every empirical improvement needs to be presented with math explaining the basis on how it was arrived at
2)Ablation studies and robustness checks
3)Use of suggestive definitions with colloquial meaning**
- 1) and 2)
- 2)
- 2) and 3)
- 1) 2) and 3)
* `[ B ]`


---

**Q: Which statement is true?**
- Increasing the number of convolutional layers increases the accuracy of the net.
- Shallow nets perform better than convolutional nets.
- Convolutional nets perform better than shallow nets.
- Shallow nets are just as good as convolutional nets.
* `[ C ]`


---

**Q: Which of the following trends have been observed and are worrisome in Machine Learning scholarship according to Lipton and Steinhardt?**
- Unreplicable results and lack of innovation
- Too much emphasis on the computational efficiency without focus on model accuracy
- Failure to distinguish between explanation and speculation
- The lack of mathematical descriptions in ML papers
* `[ C ]`


---

**Q: which statement is wrong about the common Troubling Trends?**
- Explanation vs. Speculation: Forming an intuitive theory around a concept is not an explanation. 
- Failure to identify the sources of empirical gains: Empirical study aimed at understanding can be illuminating even absent a new algorithm
- Mathiness: the best remedy for mathiness is to avoid it
- Misuse of language: Using words like  “thought vectors” and the “consciousness prior” is good , cause it helps people understanding. 
* `[ D ]`


---

**Q: Which of the following is the main disadvantage of maximum likelihood estimation method from a mathematical standpoint?**
- Mathematically they are less folded
- Less complex nature 
- Computation lucidity
- Requires intense computation
* `[ D ]`


---

**Q: Which is NOT a problem with deep learning papers as suggested by the authors of paper 4?**
- Failure to distinguish between explanation and speculation.
- Failure to identify the sources of empirical gains
- Misuse of language
- Relying to much on authority of author instead of empirical results
* `[ D ]`


---

**Q: Which of these is an (argued) cause to the downgrading quality of Machine Learning papers?**
- The rapid expansion of the community.
- The thinness of the reviewer pool.
- Misaligned incentives of scholarships vs. short-term measurement of success
- All of the above.
* `[ D ]`


---

**Q: Deconvolution is?**
- Process of reversing a convolution
- Transpose convolutions
- Up-convolutions
- Commonly found in auto-encoders
and generative adversarial networks
* `[ A ]`


---

**Q: what is the correct term to use when referring to a deep learning algorithm's performance?**
- Consciousness
- Thinking capability
- Intelligence
- generalizing capability
* `[ D ]`


---

**Q: What is NOT helpful to identify the empirical gain**
- Abliation study
- Literature study
- Robustness check
- Error analysis
* `[ B ]`


---

**Q: What is "mathiness" and why is it a problem?**
- Overly complicated maths only meant to impress / overwhelm the reader.
- The fact that novice reviewers require gratuitous use of mathematical formulas for a paper to be accepted.
- Mathiness uses a mixture of words and symbols, but instead of making tight links, it leaves ample room for slippage between statements in natural language versus formal language
- Mathiness presents speculation as mathematically rigorous statements, while not really proving anything. 
* `[ C ]`


---

**Q: Which of the following descriptions is desirable for papers published in the domain of Machine Learning?**
- Papers that detail the creative thought process which might lack a through scientific explanation, but introduces an intuitive new direction to a problem.
- Papers that abstract complex mathematical concepts behind an empirical explanation.
- Papers that avoid colloquial connotations for simplyfing complex state of art concepts.
- A relaxed review and acceptance mechanism for papers published in the domain, to possibly encourage new researchers.
* `[ B ]`


---

**Q: According to the authors a correct way to explain the theory of a paper in depth is**
- To avoid difficult equations that could be written in a paper because they may lead to mathematical inconveniences
- Only through the natural language which should be preferred as an explanatory tool of the theory
- To use the mixture of the nature language and the use of mathematical equations in more abstract way, in order to express the nature of the paper
- Through more equations, regardless of their complexity
* `[ D ]`


---

**Q: Which is the final step in dataset creation of CIFAR-10 process:**
- Assemble a set of relevant keywords for each class 
- Label the images from Tiny images
- Verify images elected by annotators and remove duplicates
- Introduce noise into the Tiny images
* `[ D ]`


---

**Q: When creating a ML paper:**
- We should focus on improvements over previous work
- We should make sure that our use of math proofs is really contributing to the explanation
- We should try to offer an explanation to new results, even if no clear causation can be proved
- We should try to use established language even if the concept we are trying to explain is a little bit different so others can relate it to previous knowledge
* `[ B ]`


---

**Q: What are downsides of the rapidly expanding ML community?**
- Experienced but over-burdened reviewers may revert to a check-list mentality
- The fraction of experienced reviewers decreases, which leads to more inexperienced reviewers
- Less experienced authors are not familiar with all previous terminology
- All of the above
* `[ D ]`


---

**Q: In the paper: Troubling Trends in Machine Learning Scholarship the authors discuss four patterns that appear to them in Machine Learning scholarship. Which is not one of them:**
- Failure to distinguish between explanation and speculation
- Incorrect or failure to add proper visual queues to make complex concepts clear to the reader.
- Mathiness: the use of mathematics that obfuscates or impresses rather than clarifies, e.g. by confusing technical and non-technical concepts.
- Misuse of language, e.g. by choosing terms of art with colloquial connotations or by overloading established technical terms.
* `[ B ]`


---

**Q: Which of the following is not a good tip for tackling machine learning scholarship troubles?**
- Clearly convey uncertainty instead of representing results as authoritive
- Mention all changes that were made when discussing (improved) results
- Avoid using too much mathematics, try using a more down-to-earth matter
- Avoid overloading terminology
* `[ B ]`


---

**Q: How does the use of suitcase words impact a quickly growing research field like deep learning according to Zachary C. Lipton and Jacob Steinhardt**
- Suitcase words lowers the bar of entry to a scientific field by "humanizing" the field
- Use of suitcase words in technical arguments can lead to confusion
- For a complex field, suitcase world can assemble reductant technical terms
- Suitcase word does not have a real impact on research fields, as they mainly are used by the press and non-experts of the given field
* `[ B ]`


---

**Q: Which of the following description is wrong?**
- We should use language to empower the reader, choosing terminology to avoid misleading or unproven connotations, collisions with other definitions, or conflation with other related but distinct concepts
- We should describe empirical investigations that consider and rule out alternative hypotheses
- We should combine intuition and evidence to aid the reader’s understanding and make paper more reliable 
- We should make clear the relationship between theoretical analysis and intuitive or empirical claims
* `[ C ]`


---

**Q: Speculation can be good and bad for the community. How can speculation result in a positively for the community?**
- Speculation rimes with speculaas which is "lekker"
- Speculation can result in triggering curiosity towards new research
- Speculation makes the paper have more authority
- Speculation and explanation go hand in hand. Thus helping the community explain some of the more difficult and non-binary subproblems arising in the field of ML.
* `[ B ]`


---

**Q: Quoting a paper on Ioffe et al., the following extract is an example of which troubling trend:

 "We define Internal Covariate Shift as the change in the
distribution of network activation due to the change in
network parameters during training"**
- Failure to distinguish explanation vs. speculation.
- Failure to identify the source of empirical gains.
- Mathiness that impresses rather than clarifies.
- Misuse of language. 
* `[ A ]`


---

**Q: Which of the following is a correct option?**
- Many aspects of the current culture are consequences of ML’s recent success, not its causes
- ML researchers are not responsible for all misrepresentations of work, it
seems likely that anthropomorphic language in authoritative peer-reviewed papers is at least partly to blame.
- Both are correct
- None of the above
* `[ C ]`


---

**Q: What should beware of as a researcher in ML **
- Distinguishing between explanation and speculation.
- Use mathematics to clarify rather than obfuscate or impress
- Identify the sources of empirical gains
- all of the three
* `[ D ]`


---

**Q: What is Overloaded terminology?**
- A technical term coined with suggestive colloquial meaning.
- Using the technical meaning of a term in a contradictory way.
- Set of terms with a single cause or origin
- None
* `[ B ]`


---

**Q: Which is not a troubling trend in the machine learning field?**
- Using explanation instead of speculation
- Failure to identify the sources of empirical gains
- The misuse of language
- Using too little mathematics
* `[ D ]`


---

**Q: The authors identify overloading several avenues of language misuse in Machine Learning papers, one of which being the overloading of technical terminology, like the term "deconvolution". What do authors of new ML papers refer to with the term "deconvolution"?**
- "up-convolution"
- "deconvolution"
- "up-convolution (deconvolution)"
- all of the above
* `[ D ]`


---

**Q: Which troubling trend describes the way that meanings of technical terminology are redefined by a set of succesive authors?**
- Suggestive Definitions
- Overloading Technical Terminology
- Suitcase Words
- Misuse of Language
* `[ B ]`


---

